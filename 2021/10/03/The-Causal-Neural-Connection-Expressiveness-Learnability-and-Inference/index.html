<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"leequant761.github.io","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="0. AbstractSCM은 mechanism과 exogeneous sources of random variation을 나타낸다. NN은 universal approximability의 특징을 갖는다. 아마 SCM의 함수를 NN으로 대체하여 학습할 수 있다는 생각을 해봤을 수 있다. 이 논문에선  expressivity와 learnability의 개념을 구">
<meta property="og:type" content="article">
<meta property="og:title" content="The Causal-Neural Connection Expressiveness, Learnability, and Inference">
<meta property="og:url" content="https://leequant761.github.io/2021/10/03/The-Causal-Neural-Connection-Expressiveness-Learnability-and-Inference/index.html">
<meta property="og:site_name" content="Study Repo">
<meta property="og:description" content="0. AbstractSCM은 mechanism과 exogeneous sources of random variation을 나타낸다. NN은 universal approximability의 특징을 갖는다. 아마 SCM의 함수를 NN으로 대체하여 학습할 수 있다는 생각을 해봤을 수 있다. 이 논문에선  expressivity와 learnability의 개념을 구">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://leequant761.github.io/2021/10/03/The-Causal-Neural-Connection-Expressiveness-Learnability-and-Inference/image-20210926195309640.png">
<meta property="og:image" content="https://leequant761.github.io/2021/10/03/The-Causal-Neural-Connection-Expressiveness-Learnability-and-Inference/image-20211003140258935.png">
<meta property="og:image" content="https://leequant761.github.io/2021/10/03/The-Causal-Neural-Connection-Expressiveness-Learnability-and-Inference/image-20211003141652831.png">
<meta property="og:image" content="https://leequant761.github.io/2021/10/03/The-Causal-Neural-Connection-Expressiveness-Learnability-and-Inference/image-20211003150738745.png">
<meta property="og:image" content="https://leequant761.github.io/2021/10/03/The-Causal-Neural-Connection-Expressiveness-Learnability-and-Inference/image-20211003233327681.png">
<meta property="og:image" content="https://leequant761.github.io/2021/10/03/The-Causal-Neural-Connection-Expressiveness-Learnability-and-Inference/image-20211003233902264.png">
<meta property="article:published_time" content="2021-10-03T14:51:57.000Z">
<meta property="article:modified_time" content="2021-10-03T14:55:45.180Z">
<meta property="article:author" content="JaeHyun Lee">
<meta property="article:tag" content="paper review">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://leequant761.github.io/2021/10/03/The-Causal-Neural-Connection-Expressiveness-Learnability-and-Inference/image-20210926195309640.png">

<link rel="canonical" href="https://leequant761.github.io/2021/10/03/The-Causal-Neural-Connection-Expressiveness-Learnability-and-Inference/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>The Causal-Neural Connection Expressiveness, Learnability, and Inference | Study Repo</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Study Repo</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://leequant761.github.io/2021/10/03/The-Causal-Neural-Connection-Expressiveness-Learnability-and-Inference/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="JaeHyun Lee">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Study Repo">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          The Causal-Neural Connection Expressiveness, Learnability, and Inference
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2021-10-03 23:51:57 / Modified: 23:55:45" itemprop="dateCreated datePublished" datetime="2021-10-03T23:51:57+09:00">2021-10-03</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Causality/" itemprop="url" rel="index"><span itemprop="name">Causality</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Disqus: </span>
    
    <a title="disqus" href="/2021/10/03/The-Causal-Neural-Connection-Expressiveness-Learnability-and-Inference/#disqus_thread" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2021/10/03/The-Causal-Neural-Connection-Expressiveness-Learnability-and-Inference/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="0-Abstract"><a href="#0-Abstract" class="headerlink" title="0. Abstract"></a>0. Abstract</h1><p>SCM은 mechanism과 exogeneous sources of random variation을 나타낸다.</p>
<p>NN은 universal approximability의 특징을 갖는다.</p>
<p>아마 SCM의 함수를 NN으로 대체하여 학습할 수 있다는 생각을 해봤을 수 있다.</p>
<p>이 논문에선</p>
<ul>
<li>expressivity와 learnability의 개념을 구분지어서 안되는 것을 보인다.</li>
<li>무엇이 데이터로부터 학습될 수 있는 지에 대한 causal hierarchy theorem(CHT)이 neural causal model(NCM)에 적용될 수 있음을 보인다.</li>
</ul>
<p>예를 들어, 단순한 임의의 complex and expressive NN은 observational data만 갖고서 interventional effect를 예측할 수 없다.</p>
<p>이 결과를 갖고서,</p>
<ul>
<li>NCM이라는 특수한 종류의 SCM을 도입하고</li>
<li>causal inference를 수행하기 위해 필요한 structural constraints를 위한 inductive bias를 formalize한다.</li>
</ul>
<p>NCM이라는 새로운 model class로 causal identification and estimation task에 집중한다.</p>
<span id="more"></span>
<h1 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h1><p>Universality가 말하길 neural model은 임의의 precision을 갖는 아무 함수를 approximate할 수 있다.</p>
<p>이 특징은 대부분의 task가 함수로 모델링 될 수 있기에, 올바른 조건 하에서 NN은 어렵고 흥미로운 AI task를 해결할 수 있다고 믿게 만든다.</p>
<p>이 믿음은 게임, 음성인식, 컴퓨터비전 등 에서 실용적인 성공에 의해 확증되어간다.</p>
<p>이 논문에선, NN의 universality를 causal reasoning의 영역에서 조사해보겠다.</p>
<p>Causal-neural connection을 이해하기 위해, 두가지 개념이 중요하다.</p>
<ol>
<li>SCM</li>
<li>Pearl Causal Hierarchy (PCH) : fully specified SCM induces a collection of distribution</li>
</ol>
<p>PCH의 중요성은 인간의 활동으로 연관지어질 수 있는 cognitive capability를 formal하게 구분짓기 때문이다.</p>
<ul>
<li>“seeing” : layer 1</li>
<li>“doing” : layer 2 : the effects of interventions</li>
<li>“imagining” : layer 3 : the counterfactuals </li>
</ul>
<p>각 layer들은</p>
<ul>
<li>구분된 formal language로 표현될 수 있고</li>
<li>inference의 종류들을 구분하는데 도움되는 query를 나타낸다.</li>
</ul>
<img src="/2021/10/03/The-Causal-Neural-Connection-Expressiveness-Learnability-and-Inference/image-20210926195309640.png" class="">
<p><strong>Fig. 1(a) 해석</strong></p>
<ul>
<li>SCM $M^\star$는 PCH의 layer들 $L_{1}^{\star}, L_{2}^{\star}, L_{3}^{\star}$을 induce한다.</li>
<li>Challenging inferential task는 $M^\star$의 일부 관측으로 PCH의 특정 layer를 recover하려고 할 때 발생한다.</li>
<li>구체적으로, intervention($L_2^\star$) effect에 대한 statement가 필요할 때, $L_1^\star$의 데이터만 passive하게 수집된 상황이 있다.</li>
</ul>
<p><strong>Fig. 1(b) 해석</strong></p>
<ul>
<li>$M^*$로 생성된 data를 사용해 neural model을 학습해보려 할 수 있다.</li>
<li>일반적인 consistency를 위해선 $N$은 $M^\star$의 generating distribution을 따라할 만큼 capable해야 한다.</li>
<li>Universality of neural model 하에서, 이는 large sample에서 만족될 것이다.</li>
<li>Question : 학습된 모델이 $M^\star$에 의해 생성된 $L_2$ distribution과 일치하는 intervention effect를 예측하는 능력이 있는 proxy로서 작동할 수 있을까?</li>
<li>Answer : Corollary1에서 일반적으로 확인될 수 없음이라고 하나, 직감적으로 말하면 $L_1 = L_1^\star$이지만 $L_2 \neq L_2^\star$인 여러 neural model이 있기 때문이다.</li>
</ul>
<hr>
<p>즉, neural model이 $M^*$를 표현할만한 능력이 있더라도, consistency w.r.t. $L_1$이 higher-layer inferences를 보장하는 데는 불충분 조건이다.</p>
<p>이에 대한 직감으로는 $L_1$이 똑같은데 $L_2$가 다른 neural model이 너무 많기 때문이다.</p>
<p>이는 causal inference 분야에서 CE identification과 estimation task에 속한다.</p>
<ol>
<li>Identification<ul>
<li>do-calculus에 기반해 많이 연구됐다.</li>
<li>$M^*$에 대한 causal diagram 또는 markov equivalence <a href="">Causal identification under Markov equivalence</a> 하에서,</li>
<li>causal query가 $P(v)$로 unique하게 결정되는 지 확인한다.</li>
<li>이 task를 해결하는 neural method는 없다.</li>
</ul>
</li>
<li>Estimation<ul>
<li>Identifiable이라고 결정됐을 때 시작하는 task이다.</li>
<li>딥러닝 테크닉이 실용적인 performance로 effect를 estimate하는 연구들은 굉장히 많이 있다.</li>
<li>Backdoor criterion (conditional ignorability) : <a href="">60, 49, 45, 30, 65, 66, 34, 61, 15, 25</a></li>
<li>O.W. (frontdoor, napkin) :  <a href="">31, 32, 33</a></li>
<li>이들은 target interventional distribution에 대응하는 특정 estimand를 최적화하는 방식이다.</li>
</ul>
</li>
</ol>
<hr>
<p>여전히 임의의 셋팅에서 $M^*$에 대한 proxy로서 NN을 generative model로서 causal identification+estimation task를 어떻게 수행할 지는 잘 알려지지 않았다.</p>
<p>real world(high dimensional domain)로 확장 가능하고, tranditional symbolic approach처럼 inference의 유효성을 보존하는 causal-neural framework를 개발하는 것이 목표이다.</p>
<p>기존에 identifiability를 위해 causal diagram이 do-calculus에 필요한 assumption을 나타냈듯이, neural causal model(NCM)은</p>
<ol>
<li>gradient descent로 적용가능하고</li>
<li>통합적인 방식으로 두 task를 수행하게하는</li>
</ol>
<p>invariances를 inductive bias로서 encode한다.</p>
<hr>
<p><strong>Contributions</strong></p>
<ul>
<li>2장에서 GD가 가능한 SCM의 특수 타입인 NCM을 소개하고, 이의 properties를 증명한다.<ul>
<li>universal expresiveness</li>
<li>certain structural invariance를 나타내는 inductive bias를 encode하는 능력</li>
<li>expressivity에도 불구하고, CHT를 준수한다.</li>
</ul>
</li>
<li>3장<ul>
<li>Neural identification problem을 formalize하고 (Def. 8)</li>
<li>causal diagram과 NCM 사이의 duality를 증명하고 (Thm. 4)</li>
<li>NCM에서 inference를 수행하는 방법을 소개하고 (Corol. 2-3)</li>
<li>NCM의 학습과 effect identifiability를 동시에 결정하는 알고리즘을 소개한다. (Alg. 1, Corol. 4)</li>
</ul>
</li>
<li>4장<ul>
<li>이러한 결과들에 기반해 GD로 CE를 identify하면서 estimate하는 알고리즘을 개발한다. (Alg. 2)</li>
</ul>
</li>
</ul>
<h2 id="1-1-Preliminaries"><a href="#1-1-Preliminaries" class="headerlink" title="1.1 Preliminaries"></a>1.1 Preliminaries</h2><p><strong>Definition 1</strong> (SCM)</p>
<p>​    An SCM is a 4-tuple $\langle\mathbf{U}, \mathbf{V}, \mathcal{F}, P(\mathbf{U})\rangle$ where</p>
<ul>
<li>$\mathbf U$ is a set of exogenous variables</li>
<li>$\mathbf V = \left\{V_{1}, V_{2}, \ldots, V_{n}\right\}$ is a set endogenous variables</li>
<li>$\mathcal F = \left\{f_{V_{1}}, f_{V_{2}}, \ldots, f_{V_{n}}\right\}$ is a set of functions s.t. $v_i = f_{V_{i}}\left(\mathbf{pa}_{V_{i}}, \mathbf{u}_{V_{i}}\right)$</li>
<li>$P(\mathbf{u})$ is a probability function defined over the domain of $\mathbf U$</li>
</ul>
<hr>
<p>각 SCM $\mathcal M$은 causal diagram $G$를 induce한다.</p>
<p>변수들간의 관계는 $\left(V_{j} \rightarrow V_{i}\right)$와 $V_{j} \leftrightarrow V_{i}$로 이뤄진다.</p>
<p>전자는 $V_j$가 $\mathbf{Pa}_{V_i}$에 속하는 경우이고, 후자는 $\mathbf{U}_{V_{i}} \cap \mathbf{U}_{V_{j}} = \not \emptyset$인 경우이다.</p>
<hr>
<p><strong>Definition 2</strong> (Layers 1, 2 Valuations)</p>
<p>​    An SCM $\mathcal M$ induces layer $L_2(\mathcal M)$ a set of interventional distributions over $\mathbf V$.</p>
<p>​    For each $\mathbf{Y} \subseteq \mathbf{V}$,</p>
<script type="math/tex; mode=display">
P^{\mathcal{M}}\left(\mathbf{y}_{\mathbf{x}}\right)=\sum_{\left\{\mathbf{u} \mid \mathbf{Y}_{\mathbf{x}}(\mathbf{u})=\mathbf{y}\right\}} P(\mathbf{u})</script><p>​    When fixed $\mathbf X = \emptyset$, it is defined as $L_1(\mathcal M)$</p>
<h1 id="2-Neural-Causal-Models-and-the-Causal-Hierarchy-Theorem"><a href="#2-Neural-Causal-Models-and-the-Causal-Hierarchy-Theorem" class="headerlink" title="2. Neural Causal Models and the Causal Hierarchy Theorem"></a>2. Neural Causal Models and the Causal Hierarchy Theorem</h1><p>이 섹션에서, expressiveness와 learnability 사이의 tension(?)을 푸는 데(?)에 집중한다.</p>
<p>이를 위해 SCM의 special class로서,</p>
<ol>
<li>Optimization을 허용하는 NN에 기반해</li>
<li>Unobserved true SCM $\mathcal M^\star$에 대한 proxy로 작동할 잠재력이 있는</li>
</ol>
<p><strong>Definition 3 </strong>(NCM)</p>
<p>​    NCM $\widehat{M}(\boldsymbol{\theta})$ over variables $\mathbf V$ with parameters $\boldsymbol{\theta}=\left\{\theta_{V_{i}}: V_{i} \in \mathbf{V}\right\}$ is an SCM $\langle\widehat{\mathbf{U}}, \mathbf{V}, \widehat{\mathcal{F}}, \widehat{P}(\widehat{\mathbf{U}})\rangle$ s.t.</p>
<ul>
<li>$\widehat{\mathbf{U}} \subseteq\left\{\widehat{U}_{\mathbf{C}}: \mathbf{C} \subseteq \mathbf{V}\right\}$<ul>
<li>$\widehat{U}_{\mathbf C}$ is associated with $\mathbf C$</li>
<li>$\mathcal D _{\widehat U_{\mathbf C}} = \left[ 0, 1\right]$</li>
</ul>
</li>
<li>$\widehat{\mathcal{F}}=\left\{\hat{f}_{V_{i}}: V_{i} \in \mathbf{V}\right\}$<ul>
<li>$\hat f_{V_i}$ is a feedforward NN parameterized by $\theta_{V_i} \in \boldsymbol \theta$</li>
<li>$V_i = \hat f_{V_i}(\mathbf{U}_{V_{i}} \cup \mathbf{P a}_{V_{i}})$</li>
<li>$\mathbf{U}_{V_{i}}=\left\{\widehat{U}_{\mathbf{C}} \in \widehat{\mathbf{U}}: V_{i} \in \mathbf{C}\right\}$</li>
</ul>
</li>
<li>$\widehat{P}(\widehat{U}_{\mathbf C}) = \operatorname{Unif}(0,1)$</li>
</ul>
<hr>
<p><strong>Remark</strong></p>
<ol>
<li>NCM은 SCM이므로, PCH layers와 관련된 distribution을 생성할 능력이 있다.</li>
<li>NCM $\in$ SCM</li>
</ol>
<hr>
<p>NCM과 SCM의 expressiveness를 비교하기 위해, consistency 개념을 formalize하겠다.</p>
<p><strong>Definition 4</strong> ($P^{(L_i)}$-Consistency)</p>
<p>​    Consider two SCMs $\mathcal M_1$ and $\mathcal M_2$.</p>
<p>​    $\mathcal M_2$ is said to be $P^{(L_i)}$-consistent w.r.t. $\mathcal M_1$ if $L_{i}\left(\mathcal{M}_{1}\right)=L_{i}\left(\mathcal{M}_{2}\right)$</p>
<p>위의 정의는 NCM뿐만 아니라 일반적인 SCM에도 적용된다.</p>
<hr>
<p>\\mbaetghiNCM은 true SCM $\mathcal M^*$의 함수들과 (observational / interventional / counterfactual) distribution을 완벽하게 표현할 수 있다.</p>
<p><strong>Theorem 1</strong> (NCM Expressiveness)</p>
<p>​    $^ \forall$SCM $\mathcal M^\star = \langle\mathbf{U}, \mathbf{V}, \mathcal{F}, P(\mathbf{U})\rangle$, $^{\exists}$NCM $\widehat{M}(\boldsymbol{\theta})=\langle\widehat{\mathbf{U}}, \mathbf{V}, \widehat{\mathcal{F}}, \widehat{P}(\widehat{\mathbf{U}})\rangle$ s.t.</p>
<ul>
<li>$\widehat{M} \text { is } L_{3} \text {-consistent w.r.t. } \mathcal{M}$</li>
</ul>
<hr>
<p>자연스러운 질문은 observational data로 학습해서 $\mathcal M^\star$의 proxy로 NCM을 사용해 inference를 수행할 수 있을 지에 대한 여부이다.</p>
<p>불행히도, 보통 안된다.</p>
<p><strong>Corollary 1</strong> (Neural Causal Hierarchy Theorem (N-CHT)).</p>
<p>​    Let $\Omega^\star$ and $\Omega$ be the sets of all SCMs and NCMs.</p>
<script type="math/tex; mode=display">
\text{Layer $j$ of the causal hierarchy for NCMs collapses to Layer $i(<j)$  relative to $M^\star \in Ω^\star$}</script><p>​    if $L_{i}\left(\mathcal{M}^{\star}\right)=L_{i}(\widehat{M})$ implies $L_{j}\left(\mathcal{M}^{\star}\right)=L_{j}(\widehat{M})$ for all $\widehat{M} \in \Omega$.</p>
<p>​    With respect to lebesgue measure over SCMs, the subset in which Layer $j$ of NCMs collapses to Layer $i$ has measure zero.</p>
<hr>
<p>Corollary 1은 NCM $\widehat {\mathcal M}$이 expressive 측면에서 SCM $\mathcal M ^{\star}$의 적합한 대체제 일지라도, PCH layers 사이의 inference가 어려다는 것을 나타낸다.</p>
<h2 id="2-1-A-Family-of-Neural-Interventional-Constraints-Inductive-Bias"><a href="#2-1-A-Family-of-Neural-Interventional-Constraints-Inductive-Bias" class="headerlink" title="2.1 A Family of Neural-Interventional Constraints (Inductive Bias)"></a>2.1 A Family of Neural-Interventional Constraints (Inductive Bias)</h2><p>Constraints about $\mathcal M^{\star}$를 알아보자.</p>
<p>이는 hypothesis space를 좁히고 valid cross-layer inference를 허용하게 해줄 수도 있다.</p>
<p>SCM은 interventional distribution $\mathcal P$와 causal diagram $\mathcal G$로 이루어져 있다.</p>
<p>$\mathcal G$는 $\mathcal P$상에 constraint를 주고 이는 cross-layer inference를 수행하는데 유용하다.</p>
<hr>
<p>간결함을 위해, observational data로부터 interventional inference을 수행하는 것에 집중한다.</p>
<p><strong>Definition 5</strong> ($\mathcal G$ -Consistency)</p>
<p>​    Let $\mathcal G$ be the causal diagram induced by SCM $\mathcal M^\star$.</p>
<script type="math/tex; mode=display">
\text{For any SCM $\mathcal M$, $\mathcal M$ is $\mathcal G$-consistent w.r.t. $\mathcal M^{\star}$}</script><p>​    , if $\mathcal G$ is a CBN for $L_2(\mathcal M)$</p>
<hr>
<p>$\mathcal M^\star$처럼 $\mathcal P$상에 constraint를 부과해야 한다.</p>
<p><strong>Definition 6</strong> ($C^2$-Component)</p>
<p>​    A subset $\mathbf C \subseteq \mathbf V$ is complete confounded component($C^2$-Component) if</p>
<ol>
<li>$^{\forall}V_{i}, V_{i} \in \mathbf{C}$, $V_i \leftrightarrow V_j$</li>
<li>$\mathbf C$ is maximal</li>
</ol>
<p><strong>Definition 7</strong> ($\mathcal G$-Constrained NCM)</p>
<p>​    Let $G$ be the causal diagram induced by SCM $\mathcal M^\star$.</p>
<p>​    Construct NCM $\widehat M$ as follows</p>
<ol>
<li>Choose $\widehat {\mathbf U}$ so that $\widehat{U}_{\mathbf{C}} \in \widehat{\mathbf{U}}$ iff $\mathbf C$ is a $C^2$-component.</li>
<li>For each $V_i \in \mathbf V$, choose $\mathbf{P a}_{V_{i}} \subseteq \mathbf{V}$ s.t. $V_j \in \mathbf {Pa}_{V_i}$ implies $V_j \rightarrow V_i$ in $\mathcal G$</li>
</ol>
<p><strong>Theorem 2</strong> (NCM $\mathcal  G$-Consistency)</p>
<p>​    Any $\mathcal G$-constrained NCM $\widehat M(\boldsymbol \theta)$ is $\mathcal G$-consistent.</p>
<hr>
<p><strong>Theorem 3</strong> ($L_2- \mathcal G$ Representation)</p>
<p>​    $^{\forall} \text{SCM }\mathcal M^{\star}$ that induces causal diagram $\mathcal G$,</p>
<p>​    $^{\exists}\mathcal G$-constrained NCM $\widehat M(\boldsymbol \theta) = \langle\widehat{\mathbf{U}}, \mathbf{V}, \widehat{\mathcal{F}}, \widehat{P}(\widehat{\mathbf{U}})\rangle$ that $L_2$-consistent w.r.t. $\mathcal M^\star$.</p>
<blockquote>
<p>NCM에 constraint를 부과함에도, 여전히 $\mathcal M^\star$의 Layer2를 나타낼만큼 expressive하다.</p>
</blockquote>
<img src="/2021/10/03/The-Causal-Neural-Connection-Expressiveness-Learnability-and-Inference/image-20211003140258935.png" class="">
<p>이 constraint를 inductive bais로 활용하면, $\widehat{\mathcal M}$은 특정 조건 하에서, $L_2$ consistency를 만족할 수 있다.</p>
<h1 id="3-The-Neural-Identification-Problem"><a href="#3-The-Neural-Identification-Problem" class="headerlink" title="3. The Neural Identification Problem"></a>3. The Neural Identification Problem</h1><p>$\mathcal G$-constarined NCM에서 causal inference가 가능한 지를 조사해보자.</p>
<img src="/2021/10/03/The-Causal-Neural-Connection-Expressiveness-Learnability-and-Inference/image-20211003141652831.png" class="">
<p><strong>Definition 8</strong> (Neural Effect Identification)</p>
<p>​    Let $\Omega^\star$ be the set of all SCMs, and $\Omega (\mathcal G)$ the set of $\mathcal G$-constrained NCMs.</p>
<p>​    The CE $P(\mathbf{y} \mid d o(\mathbf{x}))$ is said to be neural identifiable from $\Omega(\mathcal G)$ and observational data</p>
<p>​    iff </p>
<p>​    $P^{\mathcal{M}^{\star}}(\mathbf{y} \mid d o(\mathbf{x}))=P^{\widehat{M}}(\mathbf{y} \mid d o(\mathbf{x}))$ for every $(\mathcal M^\star, \widehat{\mathcal M}) \in \Omega^\star \times \Omega(\mathcal G)$ s.t.</p>
<ol>
<li>$\mathcal M^\star$ induces $\mathcal G$</li>
<li>$P(\mathbf v) = P^{\mathcal M^\star}(\mathbf v) = P^{\widehat{\mathcal M}}(\mathbf v)$</li>
</ol>
<hr>
<p><strong>Theorem 4</strong> (Graphical-Neural Equivalence (Dual ID)).</p>
<p>​    Let $\Omega ^{\star}$ be the set of all SCMs and $\Omega$ th eset of NCMs.</p>
<p>​    Consider the true SCM $\mathcal M^\star$ and the corresponding causal diagram $\mathcal G$.</p>
<p>​    Let $Q = P(\mathbf y \mid do(\mathbf x))$ be the query of interest and $P(\mathbf v)$ be the observational distribution.</p>
<p>​    Then, $Q$ is neural identifiable from $\Omega(\mathcal G)$ and $P(\mathbf v)$ iff $Q$ is identifiable from $\mathcal G$ and $P(\mathbf v)$</p>
<hr>
<p>Theorem 4는 identification이 유지됨을 의미한다.</p>
<p>NCM을 통해 inference까지 하는 것이 목표이기 때문에, theorem 4는 이게 가능함을 보장해준다.</p>
<hr>
<p><strong>Corollary 2</strong> (Neural Mutilation (Operational ID))</p>
<p>​    Consider</p>
<ul>
<li>the true SCM $\mathcal M^\star \in \Omega ^\star$</li>
<li>causal diagram $\mathcal G$</li>
<li>observational distribution $P(\mathbf v)$</li>
<li>target query $Q = P^{\mathcal M^\star}(\mathbf y \mid do(\mathbf x))$</li>
</ul>
<p>​    Let $\widehat {\mathcal M} \in \Omega (\mathcal G)$ be a $\mathcal G$-constrained NCM that is $L_1$-consistent with $\mathcal M^\star$.</p>
<p>​    If $Q$ is identifiable from $\mathcal G$ and $P(\mathbf v)$, then $Q$ is computable through a multilation process on $\widehat{\mathcal M}$</p>
<hr>
<ol>
<li>$L_1$-consistency</li>
<li>$\mathcal G$-constraint</li>
<li>identifiable</li>
</ol>
<p>일 경우에, NCM에 절단과정으로 inference가 수행될 수 있음을 나타낸다.</p>
<hr>
<p>Markovian SCM은 $U_i$가 한개의 $V_i$에만 영향을 주는 구조이고, interventional distribution이 identifiable하다.</p>
<p><strong>Corollary 3</strong> (Markovian Identification)</p>
<p>​    Whenever the $\mathcal G$-constrained NCM $\widetilde {\mathcal M}$ is Markovian, $P(\mathbf y \mid do(\mathbf x))$ is always identifiable via the proxy NCM.</p>
<hr>
<p>Non-Markovian case에 대해선 알고리즘1이 특정 effect가 observational data로 부터 identifiable한 지를 결정한다.</p>
<img src="/2021/10/03/The-Causal-Neural-Connection-Expressiveness-Learnability-and-Inference/image-20211003150738745.png" class="">
<p>놀랍게도, 이 procedure는 necessary and sufficient 하다는 것이다.</p>
<p>이는 딥러닝이 identifiability를 결정하는 데에 do-calculus처럼 강력함을 의미한다.</p>
<p><strong>Corollary 4</strong> (Soundness and Completeness)</p>
<p>​    Let $\Omega^\star$ be the set of all SCMs.</p>
<p>​    Let $\mathcal M^\star \in \Omega^\star$ be the true SCM inducing causal diagram $\mathcal G$.</p>
<p>​    Let $Q = P(\mathbf y \mid do(\mathbf x))$ be a query of interest.</p>
<p>​    Let $\widehat Q$ be the result from running Algorithm 1 w/ inputs</p>
<ul>
<li>$P^{<em>}(\mathbf{v})=L_{1}\left(\mathcal{M}^{</em>}\right)&gt;0$</li>
<li>$\mathcal G$</li>
<li>$Q$</li>
</ul>
<p>​    Then, $Q$ is identifiable iff $\widehat Q$ is not FAIL.</p>
<p>​    Moreover, if $\widehat Q$ is not FAIL, then $P^{\mathcal{M}^{*}}(\mathbf{y} \mid d o(\mathbf{x}))$.</p>
<h1 id="4-The-Neural-Estimation-Problem"><a href="#4-The-Neural-Estimation-Problem" class="headerlink" title="4. The Neural Estimation Problem"></a>4. The Neural Estimation Problem</h1><p>Identifiability가 asymptotic theory에 의해 해결됐으나, finite sample 하에서 estimating CE를 고려해보자.</p>
<p>간결함을 위해, 모든 $V_i$는 binary를 가정하겠으나, continuous variable로 확장될 수 있는 논의를 하겠다.</p>
<p>Gumbel-Max trick에 기반해서, NCM을 정의하자.</p>
<script type="math/tex; mode=display">
\begin{cases}\mathbf{V} & := \mathbf V
\\ 
\widehat{\mathbf{U}}&:=\left\{U_{\mathbf{C}}: \mathbf{C} \in C^{2}(\mathcal{G})\right\} \cup\left\{G_{V_{i}}: V_{i} \in \mathbf{V}\right\}
\\
\widehat{\mathcal{F}} & := \left\{f_{V_{i}}:=\arg \max _{j \in\{0,1\}} \left [ g_{j, V_{i}}+\left\{\begin{array}{ll}
\log \sigma\left(\phi_{V_{i}}\left(\mathbf{p a}_{V_{i}}, \mathbf{u}_{V_{i}}^{c} ; \theta_{V_{i}}\right)\right) & j=1 \\
\log \left(1-\sigma\left(\phi_{V_{i}}\left(\mathbf{p a}_{V_{i}}, \mathbf{u}_{V_{i}}^{c} ; \theta_{V_{i}}\right)\right)\right) & j=0
\end{array}\right.\right. \right]
\\ 
P(\widehat{\mathbf{U}}) & := \left\{U_{\mathbf{C}} \sim \operatorname{Unif}(0,1): U_{\mathbf{C}} \in \mathbf{U}\right\} \cup \left\{G_{j, V_{i}} \sim \operatorname{Gumbel}(0,1): V_{i} \in \mathbf{V}, j \in\{0,1\}\right\}
\end{cases}</script><script type="math/tex; mode=display">
\begin{aligned}
P^{\widehat{M}(\mathcal{G} ; \boldsymbol{\theta})}(\mathbf{v} \mid d o(\mathbf{x})) &= \sum_{\widehat{\mathbf u}}\prod_{V_i \in \mathbf V \setminus \mathbf X}P(V_i = v_i \mid \mathbf u_{V_i}) P(\widehat{\mathbf u})
\\
&= \sum_{\widehat{\mathbf u}}\prod_{V_i \in \mathbf V \setminus \mathbf X}\tilde{\sigma}_{v_{i}} P(\widehat{\mathbf u}) \quad \text{where $\tilde{\sigma}_{v_{i}}:= \begin{cases}\sigma\left(\phi_{i}\left(\mathbf{p} \mathbf{a}_{V_{i}}, \mathbf{u}_{V_{i}}^{c} ; \theta_{V_{i}}\right)\right) & v_{i}=1 \\ 1-\sigma\left(\phi_{i}\left(\mathbf{p a}_{V_{i}}, \mathbf{u}_{V_{i}}^{c} ; \theta_{V_{i}}\right)\right) & v_{i}=0\end{cases}$}
\\
&\approx \frac{1}{m} \sum_{j=1}^{m} \prod_{V_{i} \in \mathbf{V} \backslash \mathbf{X}} \tilde{\sigma}_{v_{i}} \quad \text{where $\left\{\mathbf{u}_{j}^{c}\right\}_{j=1}^{m} \sim P\left(\mathbf{U}^{c}\right)$} \quad \because \tilde{\sigma}_{v_{i}} \text{ is indep to $g_{V_i}$}
\end{aligned}</script><p>Algorithm 1의 line 2~3은 $L_1$consistency를 요구한다.</p>
<p>하지만 finite sample만 있기 때문에, data의 likelihood를 최대화하여 NCM을 estimate해야한다.</p>
<p>추가로 CE를 최대화(혹은 최소화)하기 위해, additional term을 추가하여,</p>
<script type="math/tex; mode=display">
\frac{1}{n} \sum_{k=1}^{n}-\log \widehat{P}_{m}^{\widehat{M}}\left(\mathbf{v}_{k}\right)-\lambda \log \widehat{P}_{m}^{\widehat{M}}(\mathbf{y} \mid d o(\mathbf{x}))</script><img src="/2021/10/03/The-Causal-Neural-Connection-Expressiveness-Learnability-and-Inference/image-20211003233327681.png" class="">
<p>실제론, identifiability test는 hypothesis testing에 의존하게 된다.</p>
<script type="math/tex; mode=display">
\left|f\left(\widehat{M}\left(\boldsymbol{\theta}_{\max }\right)\right)-f\left(\widehat{M}\left(\boldsymbol{\theta}_{\min }\right)\right)\right|<\tau</script><h1 id="5-Experiments"><a href="#5-Experiments" class="headerlink" title="5. Experiments"></a>5. Experiments</h1><img src="/2021/10/03/The-Causal-Neural-Connection-Expressiveness-Learnability-and-Inference/image-20211003233902264.png" class="">
<ul>
<li>8개의 SCM에 대해서</li>
<li>$\tau=0.01, 0.03, 0.05$ (파랑, 초록, 빨강) 별로 identifiability classification accuracy이고</li>
<li>1~99 percentile of max-min gap이다.</li>
</ul>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/paper-review/" rel="tag"># paper review</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2021/09/22/A-Simulation-Based-Test-of-Identifiability-for-Bayesian-Causal-Inference/" rel="prev" title="A Simulation-Based Test of Identifiability for Bayesian Causal Inference">
      <i class="fa fa-chevron-left"></i> A Simulation-Based Test of Identifiability for Bayesian Causal Inference
    </a></div>
      <div class="post-nav-item"></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    
  <div class="comments">
    <div id="disqus_thread">
      <noscript>Please enable JavaScript to view the comments powered by Disqus.</noscript>
    </div>
  </div>
  

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#0-Abstract"><span class="nav-text">0. Abstract</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#1-Introduction"><span class="nav-text">1. Introduction</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-1-Preliminaries"><span class="nav-text">1.1 Preliminaries</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#2-Neural-Causal-Models-and-the-Causal-Hierarchy-Theorem"><span class="nav-text">2. Neural Causal Models and the Causal Hierarchy Theorem</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#2-1-A-Family-of-Neural-Interventional-Constraints-Inductive-Bias"><span class="nav-text">2.1 A Family of Neural-Interventional Constraints (Inductive Bias)</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#3-The-Neural-Identification-Problem"><span class="nav-text">3. The Neural Identification Problem</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#4-The-Neural-Estimation-Problem"><span class="nav-text">4. The Neural Estimation Problem</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#5-Experiments"><span class="nav-text">5. Experiments</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">JaeHyun Lee</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">30</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">11</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">JaeHyun Lee</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

<script>
  function loadCount() {
    var d = document, s = d.createElement('script');
    s.src = 'https://leequant761.disqus.com/count.js';
    s.id = 'dsq-count-scr';
    (d.head || d.body).appendChild(s);
  }
  // defer loading until the whole page loading is completed
  window.addEventListener('load', loadCount, false);
</script>
<script>
  var disqus_config = function() {
    this.page.url = "https://leequant761.github.io/2021/10/03/The-Causal-Neural-Connection-Expressiveness-Learnability-and-Inference/";
    this.page.identifier = "2021/10/03/The-Causal-Neural-Connection-Expressiveness-Learnability-and-Inference/";
    this.page.title = "The Causal-Neural Connection Expressiveness, Learnability, and Inference";
    };
  NexT.utils.loadComments(document.querySelector('#disqus_thread'), () => {
    if (window.DISQUS) {
      DISQUS.reset({
        reload: true,
        config: disqus_config
      });
    } else {
      var d = document, s = d.createElement('script');
      s.src = 'https://leequant761.disqus.com/embed.js';
      s.setAttribute('data-timestamp', '' + +new Date());
      (d.head || d.body).appendChild(s);
    }
  });
</script>

</body>
</html>
